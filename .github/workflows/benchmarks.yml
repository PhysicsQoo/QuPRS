name: Python CI & Benchmarks

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  # ====================================================================
  # JOB 1: Build and save a new performance baseline when code is merged into main.
  # This job's sole responsibility is to run on the main branch and store
  # its performance benchmark results as a workflow artifact.
  # ====================================================================
  build-and-save-baseline:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.12"]
    steps:
      - name: Checkout main branch code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: pip install .[dev]

      - name: Run benchmark and save results as JSON
        # No path argument is needed; pytest's auto-discovery will find the 'test' directory.
        run: pytest --benchmark-only --benchmark-json=main_baseline.json

      - name: Upload benchmark baseline as artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-baseline-${{ matrix.python-version }}
          path: main_baseline.json

  # ====================================================================
  # JOB 2: For Pull Requests, run tests and compare performance against the main branch baseline.
  # This job features a robust fallback mechanism using a file-system check.
  # ====================================================================
  test-and-benchmark-pr:
    if: github.event_name == 'pull_request'
    permissions:
      pull-requests: write # Required to post comments on the PR
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.12"]
    steps:
      # --- Step 1: Prepare the Pull Request Environment ---
      - name: Checkout PR code
        uses: actions/checkout@v4

      - name: Setup Python and Install PR Dependencies
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      - name: Install PR dependencies
        run: pip install .[dev]

      # --- Step 2: Run Tests and Benchmark on the PR ---
      - name: Run Benchmark on PR code
        run: pytest --benchmark-only --benchmark-json=pr_benchmark.json

      # --- Step 3: Get or Generate the Baseline from Main ---
      - name: Get or Generate Baseline from Main
        # Add the GH_TOKEN environment variable for gh cli authentication.
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          # First, attempt to download the latest artifact from the main branch.
          echo "INFO: Attempting to download baseline artifact..."
          gh api \
            -H "Accept: application/vnd.github+json" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "/repos/${{ github.repository }}/actions/artifacts?name=benchmark-baseline-${{ matrix.python-version }}" | \
            jq '.artifacts[0].archive_download_url' | xargs curl -L -o baseline_artifact.zip
          
          # Unzip the artifact. The '||' operator silences errors if the file doesn't exist.
          unzip -o baseline_artifact.zip || echo "INFO: No artifact found or failed to unzip."

          # The robust check: if the baseline JSON file does not exist after the download attempt,
          # then execute the on-the-fly generation logic.
          if [ -f "main_baseline.json" ]; then
            echo "‚úÖ SUCCESS: Baseline 'main_baseline.json' obtained from artifact."
          else
            # Fallback Plan: Generate the baseline from the main branch in an isolated environment.
            echo "‚ö†Ô∏è WARNING: Baseline not found. Generating from main branch on-the-fly."
            
            echo "INFO: Cloning main branch into 'main_code' directory..."
            git clone "https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}" main_code --branch main --single-branch

            cd main_code

            echo "INFO: Creating and activating a separate venv for the main branch to prevent environment pollution..."
            python -m venv .venv
            source .venv/bin/activate
            
            echo "INFO: Installing dependencies for main branch inside its venv..."
            pip install --upgrade pip
            pip install .[dev]

            echo "INFO: Running benchmark on main branch inside its venv..."
            # The path '../test' is required here because the current working directory is 'main_code'.
            # '|| true' ensures that even if this benchmark fails, it won't fail the entire PR check.
            pytest --benchmark-only --benchmark-json=../main_baseline.json ../test || true
            
            cd ..
            echo "INFO: Deactivated and finished with the temporary venv."
          fi

      # --- Step 4: Compare, Report, and Comment ---
      - name: Compare benchmarks and generate final JSON report
        run: |
          # Final safety check: if the baseline file still doesn't exist, create an empty one.
          if [ ! -f "main_baseline.json" ]; then
            echo "‚ùå ERROR: Failed to obtain or generate baseline. Creating an empty one for a safe run."
            echo '{"benchmarks": []}' > main_baseline.json
          fi

          echo "INFO: Comparing PR benchmark against the obtained baseline."
          pytest --benchmark-compare=main_baseline.json \
                 --benchmark-storage=file://. \
                 --benchmark-compare-fail=mean:10% \
                 --benchmark-json=comparison_results.json

      - name: Generate benchmark markdown report
        run: python src/generate_benchmark_report.py

      - name: Upload benchmark report artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-report-${{ matrix.python-version }}
          path: |
            benchmark_report.md
            comparison_results.json

      - name: Comment benchmark results on PR
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          path: benchmark_report.md
          header: "üîç Benchmark Comparison Report (Python ${{ matrix.python-version }})"