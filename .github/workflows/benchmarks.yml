name: Python CI & Benchmarks

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build-and-save-baseline:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.12"]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install .[dev]

      - name: Run benchmark on main
        run: |
          mkdir -p result
          pytest --benchmark-only \
                 --benchmark-json=main_baseline.json

      - name: Upload benchmark artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-main-${{ matrix.python-version }}
          path: main_baseline.json

  test-and-benchmark:
    if: github.event_name == 'pull_request'
    permissions:
      pull-requests: write
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.12"]
    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.head_ref }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install .[dev]

      - name: Run Unit Tests on PR
        run: pytest -n auto -v

      - name: Run Benchmark on PR code and generate result
        run: |
          pytest --benchmark-only \
                 --benchmark-json=pr_benchmark.json 

      - name: Get baseline from main branch
        run: |
          # Strategy 1: Try to download baseline artifact from main branch
          echo "INFO: Attempting to download baseline artifact from main branch..."
          gh_token="${{ secrets.GITHUB_TOKEN }}"
          curl -L \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer $gh_token" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs?branch=main&status=success&per_page=1" | \
            jq -r '.workflow_runs[0].artifacts_url' | \
            xargs -I {} curl -L -o artifact.zip -H "Authorization: Bearer $gh_token" {}

          unzip -o artifact.zip || echo "INFO: No artifact found or failed to unzip."

          # Check if baseline file exists
          if [ -f "main_baseline.json" ]; then
            echo "‚úÖ SUCCESS: Baseline artifact 'main_baseline.json' found."
          else
            # Strategy 2: If artifact does not exist, generate on-the-fly by checking out main branch
            echo "‚ö†Ô∏è WARNING: Baseline artifact not found. Attempting to generate from main branch on-the-fly."
            
            # Use actions/checkout to cleanly checkout main into a separate directory
            git config --global --add safe.directory /github/workspace/main_code
            git clone "https://x-access-token:$gh_token@github.com/${{ github.repository }}" main_code --branch main --single-branch
            
            cd main_code
            echo "INFO: Installing dependencies for main branch..."
            python -m pip install --upgrade pip
            pip install .[dev] || echo "ERROR: Failed to install deps on main"
            
            echo "INFO: Running benchmark on main branch..."
            # Run pytest, continue even if it fails (|| true) to avoid failing the whole CI
            pytest --benchmark-only --benchmark-json=../main_baseline.json tests/ || true
            cd ..
          fi

          # Strategy 3: Final check, if baseline file still does not exist, create an empty one
          if [ ! -f "main_baseline.json" ]; then
            echo "‚ùå ERROR: Failed to generate baseline from main. Creating an empty baseline as a final fallback."
            echo '{"benchmarks": []}' > main_baseline.json
          fi

      - name: 6. Compare benchmarks and generate report
        run: |
          echo "INFO: Comparing PR benchmark against the obtained baseline."
          pytest --benchmark-compare=main_baseline.json \
                 --benchmark-storage=file://. \
                 --benchmark-compare-fail=mean:10% \
                 --benchmark-json=comparison_results.json
          
      - name: Generate benchmark markdown report
        run: |
          python src/generate_benchmark_report.py

      - name: Upload benchmark report artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-report-${{ matrix.python-version }}
          path: |
            benchmark_report.md
            comparison_results.json

      - name: Comment benchmark results on PR
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          path: benchmark_report.md
          header: "üîç Benchmark Comparison Report (Python ${{ matrix.python-version }})"
