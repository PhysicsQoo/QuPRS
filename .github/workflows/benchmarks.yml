name: Python CI & Benchmarks

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build-and-save-baseline:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.12"]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install .[dev]

      - name: Run benchmark on main
        run: |
          mkdir -p benchmarks
          pytest --benchmark-only \
            --benchmark-save=main \
            --benchmark-storage=file://./benchmarks

      - name: Upload benchmark artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-main-${{ matrix.python-version }}
          path: benchmarks/**/*.json

  test-and-benchmark:
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    needs: build-and-save-baseline
    strategy:
      matrix:
        python-version: ["3.12"]
    steps:
      - name: Checkout PR Code
        uses: actions/checkout@v4

      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install .[dev]

      - name: Run tests
        run: pytest -n auto -v

      - name: Download main benchmark baseline
        uses: actions/download-artifact@v4
        with:
          name: benchmark-main-${{ matrix.python-version }}
          path: benchmarks

      - name: Run benchmark on PR branch
        run: |
          pytest --benchmark-only \
            --benchmark-save=pr \
            --benchmark-storage=file://./benchmarks

      - name: Compare benchmark with main
        run: |
          pytest --benchmark-compare \
            --benchmark-storage=file://./benchmarks \
            --benchmark-compare-fail=mean:10% \
            --benchmark-json=comparison_results.json

      - name: Generate benchmark markdown report
        run: |
          echo "## Benchmark Comparison Results" > benchmark_report.md
          python -m json.tool comparison_results.json >> benchmark_report.md

      - name: Upload benchmark report artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-report-${{ matrix.python-version }}
          path: |
            benchmark_report.md
            comparison_results.json

      - name: Comment benchmark results on PR
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          path: benchmark_report.md
          header: "üîç Benchmark Comparison Report (Python ${{ matrix.python-version }})"
